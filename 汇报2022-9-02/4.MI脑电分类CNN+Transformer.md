---
headingNumber: true
enableMacro: true
customVar: Hello
define:
    --Author--: ProtoDrive000
    --te--: ==transformer encoders==
    --sa--: ==self-attention==
---
# 4.MI脑电分类CNN+Transformer

| 论文名称 |EEG classification algorithm of motor imagery based on CNN-Transformer fusion network |
| -- | -- | 
| 期刊 |None / July 6, 2022|
| 方法 |本文提出了一种基于Transformer的一维卷积神经网络模型(CNNTransformer)，用于四类运动图像脑电信号的分类和识别。首先，通过带通滤波和PCA降维等预处理，去除原始EEG的伪影，构造新的时空频率特征；然后通过1D-CNN的卷积和合并操作提取时间维度上的局部特征，同时降低特征的时间维度；接下来，使用基于注意机制的变换器从多个角度提取更抽象和更高级的时间特征；最后，通过全连接层对分类结果进行集成和输出。|
| 结论 |使用竞争数据集2008 BCI竞争2A评估CNN-Transformer模型的性能。结果表明，CNN-Transformer模型的平均精度和kappa值分别高达99.29%(±0.07%)和98.43%(±1.21)，比经典结构(CNN-LSTM)高3.72%和7.68%。|
| 评价 |Transformer的结构设计比较有创新|
---
## 主要工作
(1)根据MI-EEG的原始特征，在空间域，将原始MI-EEG按**不同频带进行分解**，然后将分解后的不同频带的特征序列融合，构建新的空间特征，并使用==PCA==提取空间维度的主要特征；对于频域，根据滤波结果，计算每个信道的每个频带的==差分熵==，并将其转换为**一维特征序列**；对于时域，通过将频域中处理的特征序列与时域本身的特征序列相结合来构造新的时频特征，然后**通过滑动窗口降低时频特征的维数**，这也解决了数据量小的问题。

(2) 为了解决长EEG时频序列导致的**分析能力差**、**计算量大**、**局部特征捕获能力弱**的问题，设计了`CNN-Transformer`模型。通过时频域中的`1D-CNN卷积`和合并操作，提取Transformer的低阶时频特征，并降低Transformer的时频特征维数，为后续Transformer提取高阶特征铺平道路。

(3) 使用**交叉验证**等优化算法优化模型`CNN-Transformer`的参数和结构。最后，基于相同的数据集，本文提出的模型与经典结构`CNN-LSTM`等其他模型进行了对比分析，验证了模型的有效性和实用性。
## 数据预处理
采用`五阶Butterworth`滤波器对样本数据集的每个片段进行滤波和分解成5个新的数据集，然后在空间维度上融合这5个波段的数据集并将数据结构==重塑==为`[288,1000,110]`，之后，空间特征被提取并通过`PCA`缩小，其缩小的数据集结构为`[288,1000,32]`

将$T_n＝(T_1，T_2，…，T_n)$定义为包含4S的EEG信号。根据初始滤波的结果，计算所有信道的不同频带的==差分熵==，将其转换为一维序列并定义为$D_m=(D_1，D_2，…，D_m)$。通过**时间序列**和**差分熵序列**的拼接形成新的时频特征序列$S_k=(S_1，S_2，…，S_k)$。为了使模型更好地学习特征并解决数据量小的问题，通过**步长为60**和**窗口大小为510**的滑动窗口将数据集矩阵划分为时间步长。每个PART包括510个样本序列。最后，为每个对象形成具有`[2880,510,32]`结构的可训练集数据。

整合数据集按6:2:2分为三部分，其中60%为训练模型的训练集；20%为验证集，用于优化模型参数；剩下的20%是测试集，用于评估模型的泛化和稳定性。


##  CNN-LSTM网络结构
### 步骤
- 首先，将预处理过程中预提取的空间特征和时间步长作为CNN-LSTM的输入，通过CNN提取EEG数据时频维度的低层特征
- 然后将所提出的特征输入到LSTM，以获得更抽象的高层代表性时频特征
- 最后，通过全连通层对所有特征进行整合，得到分类结果
![Img](https://imgpool.protodrive.xyz/img/yank-note-picgo-img-20220905131912.png#pic_center%20=400x)
### 细节参数

| 参数描述 | 数值/方法 |
| -- | -- |
|每个受试者的数据结构|[2880,510,32]|
|模型的输入|[32,510]|
|信道和频带融合后的空间特征维数|32|
|采样点是时间特征|510|
|第一卷积层的核大小|4|
|第一卷积层的核数目|128|
|第一激活函数|ReLu|
|池化层maximum pool大小|4|
|第二卷积层的核大小|2|
|第二卷积层的核数目|64|
|第二激活函数|ReLu|
|batch标准化维度|64|
|LSTM层激活函数|tanh|
|dropout|0.1|
|每个LSTM层的总单元数|25|
|完全连接层激活函数|softmax|



## CNN-Transformer网络结构
### 步骤
- 首先，通过卷积和合并的`1D-CNN`操作在时间频率维度上进行下采样，捕获局部时间频率特征，并且进一步减少时间序列的长度。此外，该过程在某种程度上可防止模型过度拟合。

- 提取的短序列时间频率特征然后被馈送到`Transformer`中，以进一步提取更抽象的高级时间特征

- 最后，通过**全连接层**集成高级抽象特征，以输出分类结果。
![Img](https://imgpool.protodrive.xyz/img/yank-note-picgo-img-20220905133116.png#pic_center%20=400x)
### Transformer
- 首先，使用`1D-CNN`的输出向量作为输入特征向量$X＝{X_1，X_2，…，X_n}$，通过==位置编码PE==记录特征向量X的初始位置信息

- 然后使用`PE特征向量`作为编码器的输入。在编码器中，为了能够并行提取**多角度时间特征以及解决梯度消失和梯度爆炸问题**，通过==多头注意机制==并行计算每个注意头的值，并将`attention head values`输入到`残差结构`和`归一化层`进行处理

- 然后将新结果输入==前馈神经网络==，再将输出结果输入解码器。解码器有两个输入，一个是编码器输出的特征向量$Z={Z_1，Z_2，…，Z_n}$，另一个是`1D-CNN`输出的特征矢量$X_1$。
在解码器中，`1D-CNN`的输出向量X与`1D-CNN`的输出向量X组合，用类似编码器的结构对输入进行解码.
### 模型参数大小
![Img](https://imgpool.protodrive.xyz/img/yank-note-picgo-img-20220905133249.png#pic_center%20=400x)

### Transformer细节参数

| 参数描述 | 数值/方法 |
| -- | -- |
|PE层的embedding尺寸|64|
|单个时间步长|125|
|dropout|0.1|
|特征向量维数|64|
|多头注意头数|16|
|前馈神经网络维数(dim_fre)|16|
|dropout|0.1|
|完全连接层激活函数|softmax|
|损失函数|Cross_entrop|
|Epoch|200|
|Learning_rate |0.0005|
## 结果
![Img](https://imgpool.protodrive.xyz/img/yank-note-picgo-img-20220905152540.png#pic_center%20=400x)
5倍交叉验证后，设定精度和kappa的平均值分别为0.9929（±0.0007）和0.9843（±0.0021）。
![Img](https://imgpool.protodrive.xyz/img/yank-note-picgo-img-20220905152813.png#pic_center%20=400x)
![Img](https://imgpool.protodrive.xyz/img/yank-note-picgo-img-20220905152854.png#pic_center%20=400x)
![Img](https://imgpool.protodrive.xyz/img/yank-note-picgo-img-20220905152901.png#pic_center%20=400x)

## 补充
### 数据集描述
2008年BCI竞赛–Graz数据集A的实验数据来自2008年国际脑-计算机接口竞赛。数据集由4个类别的9名受试者的MI-EEG组成，即左手(1类)、右手(2类)、脚(3类)和舌头(4类)。每个受试者的实验程序和内容相同。实验内容为：每个受试者在不同时间点记录2组实验数据，每组包括6组小实验，每组小实验包含48个片段(即：4种动作，每种动作随机重复12次，共4×12=48次)，每组实验数据共包含288个截面(6组×12个截面=288个)，2组实验数据共有576个截面(2组×6组×48个截面=576个)。由于一组实验不包含训练所需的标签，因此本文仅使用带有标签的实验数据集。
![Img](https://imgpool.protodrive.xyz/img/yank-note-picgo-img-20220905125553.png#pic_center%20=400x)

实验过程如下：在测试开始时(t=0s)，黑屏上会出现一个固定的十字，除了一个简短的可听到的提示音，两秒钟后(t=2s)，一个十字会左右指向作为提示，向下或向上(对应于左手运动、右手运动、脚运动和舌头运动的四类)箭头将在屏幕上出现约1.25s，这提示受试者想象与图片对应的运动，每个受试者被要求完成这些想象任务，直到屏幕上的十字消失(t=6s)，然后短暂休息直到屏幕再次变黑，并分阶段重复该过程288次。
为了实验的准确性，我们仅截取提示后4s的数据作为单个MI-EEG样本。然后，通过工具包MNE Python(MNE是一个开源Python工具包，主要用于EEG/MEG分析、处理和可视化)，为每个受试者构建了一个大小为22×1000×288的MI-EEG数据样本。
