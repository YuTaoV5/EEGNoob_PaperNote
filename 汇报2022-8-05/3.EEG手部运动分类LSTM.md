---
headingNumber: true
enableMacro: true
customVar: Hello
define:
    --Author--: ProtoDrive000
---
# EEG手部运动分类LSTM
| 论文名称 | Classification of Hand Movements from EEG using a Deep Attention-based LSTM Network|
| -- | -- | 
| 期刊 | IEEE SENSORS JOURNAL 4.325/Q1|
| 方法 | 本文提出了一种基于注意机制的LSTM网络的左手/右手运动分类深度学习方法。我们提出的方法包括三个主要步骤:1)对数据进行预处理，以减少信号伪影的负面影响，包括串扰、噪声和电力线干扰;ii)从脑电中提取时域和频域特征，作为LSTM输入层的输入;设计了一种基于注意的LSTM网络来学习随时间变化的脑电图信息的重要性，其中重要性越高的判别信息被赋予越高的分数，以更好地促进分类性能。 |
| 结论 | i)提出的深度模型，使用10倍交叉学科验证方案对所有可用数据(103名受试者)进行了训练，显著优于最先进的手部运动分类解决方案。ii)为了将我们的工作与以前使用相同数据集的研究进行比较，我们还对103名受试者分别进行了受试者内部分类(使用相同的网络)，并取得了非常高的准确性，超过了以前的研究。iii)最后，我们对不同刺激感知阶段和手部运动阶段的大脑活动进行了详细分析，并证明通过传感器对的脑电图信息流与大脑已知和预期的神经功能相对应。|
---
## 数据处理
一个==陷波滤波器==去除50 Hz的电源线干扰，一个==带通滤波器==允许0.5´70 Hz的频率范围通过，从而最大限度地减少该频率范围[24]中经常出现的噪声等伪影。最后对脑电信号幅值进行==归一化处理==，利用最小-最大归一化方法减小不同受试者间的脑电信号幅值差异。
## 时域和频域特征提取
脑电图是一种非平稳的时间序列信号，其非线性特征经常用于表征和分类任务。每次实验以2秒为一段进行特征提取。
|特征|公式|
|--|--|
|平均值|$\mu=\frac{1}{N} \sum_{i=1}^{N} x_{i}$|
|方差|$\sigma^{2}=\frac{1}{N} \sum_{i=1}^{N}\left(x_{i}-\mu\right)^{2}$|
|偏斜系数|$S=\frac{\frac{1}{N} \sum_{i=1}^{N}\left(x_{i}-\mu\right)^{3}}{\left(\frac{1}{N-1} \sum_{i=1}^{N}\left(x_{i}-\mu\right)^{2}\right)^{3 / 2}}$|
|峰度|$K=\frac{\frac{1}{N} \sum_{i=1}^{N}\left(x_{i}-\mu\right)^{4}}{\left(\frac{1}{N} \sum_{i=1}^{N}\left(x_{i}-\mu\right)^{2}\right)^{2}}-3$|
|零交叉点|$z c=\sum_{i=1}^{N-1} 1_{\mathbb{R}<0}\left(x_{i} x_{i-1}\right)$|
|信号下绝对面积|$s i m p s=\int_{a}^{b}abs[f(x)] d x$|
|峰峰值|$p k 2 p k=\max (\mathbf{x})-\min (\mathbf{x})$|
|振幅谱密度|$\hat{X}(\omega)=\frac{1}{\sqrt{T}} \int_{0}^{T} x(t) \exp { }^{-i \omega t} d t$|
|功率谱密度|$S_{x x}(\omega)=\lim _{T \rightarrow \infty} E\left[{abs(\hat{X}(\omega))}^{2}\right]$|
|各频段功率|$P=\frac{1}{\pi} \int_{\omega_{1}}^{\omega_{2}} S_{x x}(\omega) d \omega$|

从每个时间步中总共提取了297个特征(27个通道 * 每个通道11个特征)。

## 深度学习方案
RNN可以用于从脑电图时间序列等序列数据中提取更高维度的依赖性。RNN单元不仅在随后的层之间有连接，而且它们之间也有连接，从以前的输入中获取信息。传统的RNN可以很容易地学习短期依赖;然而，由于梯度问题的消失和爆发，它们在学习长期动态方面存在困难。LSTM是一种RNN，通过学习长期和短期依赖来解决消失和爆炸梯度问题。
### LSTM
LSTM网络由==细胞==组成，细胞的输出根据过去的记忆内容通过网络演进。

这些细胞有一个共同的细胞状态，在整个细胞LSTM链上保持长期依赖关系。然后，信息流由==输入门==(it)和==忘记门==(ft)控制，从而允许网络决定是忘记之前的状态$C_{t-1}$还是用新信息更新当前状态$C_{t}$。每个单元的输出(隐藏状态)由一个==输出门==$o_{t}$控制，允许单元计算其输出给定更新的单元状态.

![Img](https://imgpool.protodrive.xyz/img/yank-note-picgo-img-20220808030020.png#pic_center%20=400x)

描述LSTM单元结构的公式如下:
$$\mathbf{i}_{\mathbf{t}}=\sigma\left(\mathbf{W}_{\mathbf{i}} \cdot\left[\mathbf{h}_{\mathbf{t}-\mathbf{1}}, \mathbf{x}_{\mathbf{t}}\right]+\mathbf{b}_{\mathbf{i}}\right)$$
$$\mathbf{f}_{\mathbf{t}}=\sigma\left(\mathbf{W}_{\mathbf{f}} \cdot\left[\mathbf{h}_{\mathbf{t}-\mathbf{1}}, \mathbf{x}_{\mathbf{t}}\right]+\mathbf{b}_{\mathbf{f}}\right)$$
$$\mathbf{C}_{\mathbf{t}}=\mathbf{f}_{\mathbf{t}} * \mathbf{C}_{\mathbf{t}-\mathbf{1}}+\mathbf{i}_{\mathbf{t}} * \tanh \left(\mathbf{W}_{\mathbf{c}} \cdot\left[\mathbf{h}_{\mathbf{t}-\mathbf{1}}, \mathbf{x}_{\mathbf{t}}\right]+\mathbf{b}_{\mathbf{c}}\right)$$
$$\mathbf{o}_{\mathbf{t}}=\sigma\left(\mathbf{W}_{\mathbf{o}} \cdot\left[\mathbf{h}_{\mathbf{t}-\mathbf{1}}, \mathbf{x}_{\mathbf{t}}\right]+\mathbf{b}_{\mathbf{o}}\right)$$
$$\mathbf{h}_{\mathbf{t}}=\mathbf{o}_{\mathbf{t}} * \tanh \left(\mathbf{C}_{\mathbf{t}}\right)$$


$$ \sigma(x)=\frac{1}{1+e^{-x}}, \tanh (x)=\frac{2}{1+e^{-2 x}}-1 $$
ht是时间步长t时的隐藏状态，$C_{t-1}$是时间步长t时的细胞状态，xt是馈入细胞的输入特征，$W_f$, $W_i$, $W_c$, $W_o$是权重，$b_f$, $b_i$, $b_c$, $b_o$是通过时间反向传播可以得到的偏差。
### 注意机制
注意机制通过将注意力集中在具有最具辨别性信息的特定时间步上，可以提高LSTM的性能。与传统的LSTM网络使用其最后的隐藏状态作为输出不同，带有注意机制的LSTM网络将输出的隐藏状态乘以可训练权值，从而捕获更多与任务相关的鉴别特征。可以表述为:
$$
\mathbf{h}_{\mathbf{i}}=\operatorname{LSTM}\left(\mathbf{s}_{\mathbf{i}}\right), i \in[1, L]
$$
hi为第i个输入对应的第i个LSTM细胞的输出隐藏状态向量，L为LSTM网络中每个递归层的细胞数。为了捕捉每个隐藏状态的重要性，注意机制定义如下:
$$
\begin{array}{c}
\mathbf{u}_{\mathbf{i}}=\tanh \left(\mathbf{W}_{\mathbf{s}} \mathbf{h}_{\mathbf{i}}+\mathbf{b}_{\mathbf{s}}\right) \\
\alpha_{\mathbf{i}}=\frac{\exp \left(\mathbf{u}_{\mathbf{i}}\right)}{\sum_{j} \exp \left(\mathbf{u}_{\mathbf{j}}\right)} \\
\mathbf{v}=\sum_{i} \alpha_{\mathbf{i}} \mathbf{h}_{\mathbf{i}}
\end{array}
$$
其中向量v是注意层的输出，$W_s$和$b_s$是可训练参数。
### 网络结构
每个片段的7个时间步中的所有297个特征，被送入第一LSTM层的7个单个细胞。我们在网络中使用了三个堆叠的7个单元层。最后的LSTM层之后是注意层，注意层之后是具有sigmoid激活函数的全连接层，用来预测每个类的概率。
![Img](https://imgpool.protodrive.xyz/img/yank-note-picgo-img-20220808030039.png#pic_center%20=400x)
### 窗口选择
运动段(2秒长的LSTM序列由7个时间步组成，相邻窗口之间有50%的重叠)，以及在训练/分类过程中使用的滑动窗口。
![Img](https://imgpool.protodrive.xyz/img/yank-note-picgo-img-20220808031327.png#pic_center%20=400x)
### LSTM超参数
超参数包括:循环深度、批大小、训练周期数、LSTM隐藏层大小、输入层和以下三个堆叠的LSTM层(D0, D1, D2, D3)后应用的dropout率，以及每个LSTM层的权重矩阵L2正则化系数。此外，还为随机Adam优化器调整了一些超参数，如学习速率(lr)和第一和第二运动估计的指数衰减率(β1和β2)。
![Img](https://imgpool.protodrive.xyz/img/yank-note-picgo-img-20220808171854.png#pic_center%20=400x)

表三给出了这些参数的最佳值。为每个验证方案(交叉主题和内部主题)分配了一组不同的参数，以最大化性能。采用二元交叉熵损失函数
$$ L=-y \log (p)+(1-y) \log (1-p) $$

验证协议和基准测试
使用真阳性(TP)、假阴性(FN)、假阳性(FP)和真阴性(TN)来计算性能
- 精确性Precision $=\frac{T P}{T P+F P}$
- 召回率Recall $=\frac{T P}{T P+F N}$
- 准确度Accuracy $=\frac{T P+T N}{T P+T N+F P+F N}$

## 结论
### 节的大小比较
![Img](https://imgpool.protodrive.xyz/img/yank-note-picgo-img-20220808032336.png#pic_center%20=400x)

为了选择最优的Segment Size用于特征提取，我们分别在0.25、0.5、0.75、1.0、1.25、1.5、1.75和2.0秒的Segment Size上进行实验，并通过交叉学科验证评估模型的性能。由表IV可知，当分段长度为2秒时，经过10次交叉验证，分类准确率最高，标准差最小。因此，在本研究中，我们将segment size设为2秒进行特征提取和分类。
### 与其他方案比较
![Img](https://imgpool.protodrive.xyz/img/yank-note-picgo-img-20220808032559.png#pic_center%20=400x)


![Img](https://imgpool.protodrive.xyz/img/yank-note-picgo-img-20220808032547.png#pic_center%20=400x)
结果表明，与其他方法相比，我们提出的模型具有良好的鲁棒性能。结果表明，我们提出的模型显著优于最佳性能基准，即PLV，有相当大的5%的准确性。此外，表VI报告了受试者内方案的准确率、精密度和召回率，表现出近乎完美的性能.
为了分析不同特征的贡献，我们使用随机森林(Random Forest, RF)进行特征排序，计算每个特征的重要性。
![Img](https://imgpool.protodrive.xyz/img/yank-note-picgo-img-20220808032957.png#pic_center%20=400x)
